{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d539b3a6-fa63-4ac1-a251-b8656ce63356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contr√¥les :\n",
      "  - SOURIS : Dessiner un rectangle autour de l'objet\n",
      "  - 'r'    : R√©initialiser la s√©lection\n",
      "  - 'q'    : Quitter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moura\\AppData\\Local\\Temp\\ipykernel_52180\\3878625284.py:82: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  idx = int((angle + 22.5) / 45.0) % 8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 194\u001b[0m\n\u001b[0;32m    191\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 155\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    152\u001b[0m direction_text \u001b[38;5;241m=\u001b[39m get_cardinal_direction(angle) \u001b[38;5;28;01mif\u001b[39;00m speed \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Barre d'info\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m info_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVitesse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m px/frame | Direction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mangle\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.0f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m deg)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(display_frame, info_text, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.7\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# 3. Code couleur de l'√©tat\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Param√®tres pour l'algorithme de Farneb√§ck (Optimis√© pour un compromis vitesse/pr√©cision)\n",
    "FARNEBACK_PARAMS = dict(\n",
    "    pyr_scale=0.5,   # √âchelle de la pyramide (0.5 = pyramide classique)\n",
    "    levels=3,        # Nombre de niveaux dans la pyramide\n",
    "    winsize=15,      # Taille de la fen√™tre de lissage (plus grand = plus robuste au bruit, mais plus flou)\n",
    "    iterations=3,    # It√©rations par niveau\n",
    "    poly_n=5,        # Taille du voisinage pour l'expansion polynomiale\n",
    "    poly_sigma=1.2,  # √âcart-type gaussien\n",
    "    flags=0\n",
    ")\n",
    "\n",
    "# Seuil pour consid√©rer qu'il y a mouvement (filtre le bruit de la cam√©ra)\n",
    "MAGNITUDE_THRESHOLD = 2.0 \n",
    "\n",
    "# Pas d'√©chantillonnage pour l'affichage des vecteurs (pour ne pas surcharger l'image)\n",
    "STEP = 10 \n",
    "\n",
    "# --- VARIABLES GLOBALES ---\n",
    "selection_rect = None # (x, y, w, h)\n",
    "drawing = False\n",
    "ix, iy = -1, -1\n",
    "\n",
    "# --- GESTION DE LA SOURIS ---\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, selection_rect\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "        selection_rect = None # Reset de la s√©lection pr√©c√©dente\n",
    "        \n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            selection_rect = (min(ix, x), min(iy, y), abs(x - ix), abs(y - iy))\n",
    "            \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        selection_rect = (min(ix, x), min(iy, y), abs(x - ix), abs(y - iy))\n",
    "        # √âviter les rectangles minuscules\n",
    "        if selection_rect[2] < 10 or selection_rect[3] < 10:\n",
    "            selection_rect = None\n",
    "\n",
    "# --- ANALYSE DU FLOT ---\n",
    "def analyze_flow_in_roi(flow, roi_gray):\n",
    "    \"\"\"\n",
    "    Extrait les statistiques de mouvement dans la zone d'int√©r√™t.\n",
    "    \"\"\"\n",
    "    # S√©paration des composantes horizontale (fx) et verticale (fy)\n",
    "    fx, fy = flow[..., 0], flow[..., 1]\n",
    "    \n",
    "    # Conversion en coordonn√©es polaires (Magnitude = Vitesse, Angle = Direction)\n",
    "    mag, ang = cv2.cartToPolar(fx, fy, angleInDegrees=True)\n",
    "    \n",
    "    # --- FILTRAGE DU BRUIT (CRUCIAL) ---\n",
    "    # On ne garde que les pixels qui bougent assez vite\n",
    "    motion_mask = mag > MAGNITUDE_THRESHOLD\n",
    "    \n",
    "    # Si peu de mouvement d√©tect√©, on retourne des valeurs nulles\n",
    "    if np.count_nonzero(motion_mask) < 10:\n",
    "        return 0.0, 0.0, motion_mask, mag, ang\n",
    "\n",
    "    # --- CALCUL DES MOYENNES ---\n",
    "    # Vitesse moyenne des pixels en mouvement uniquement\n",
    "    avg_speed = np.mean(mag[motion_mask])\n",
    "    \n",
    "    # Pour la direction moyenne, on ne peut pas faire la moyenne des angles (probl√®me 0¬∞/360¬∞)\n",
    "    # On fait la moyenne des vecteurs (fx, fy) puis on convertit\n",
    "    avg_fx = np.mean(fx[motion_mask])\n",
    "    avg_fy = np.mean(fy[motion_mask])\n",
    "    _, avg_angle = cv2.cartToPolar(np.array([avg_fx]), np.array([avg_fy]), angleInDegrees=True)\n",
    "    \n",
    "    return avg_speed, avg_angle[0], motion_mask, mag, ang\n",
    "\n",
    "def get_cardinal_direction(angle):\n",
    "    \"\"\"Convertit un angle en degr√©s en direction textuelle.\"\"\"\n",
    "    directions = [\"Est (Droite)\", \"Sud-Est\", \"Sud (Bas)\", \"Sud-Ouest\", \"Ouest (Gauche)\", \"Nord-Ouest\", \"Nord (Haut)\", \"Nord-Est\"]\n",
    "    # L'angle 0 est l'Est dans OpenCV, tourne dans le sens horaire\n",
    "    idx = int((angle + 22.5) / 45.0) % 8\n",
    "    return directions[idx]\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "def main():\n",
    "    global selection_rect\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "        return\n",
    "\n",
    "    cv2.namedWindow('Flot Optique - Farneback')\n",
    "    cv2.setMouseCallback('Flot Optique - Farneback', draw_rectangle)\n",
    "\n",
    "    prev_gray = None\n",
    "    prev_roi_frame = None\n",
    "\n",
    "    print(\"Contr√¥les :\")\n",
    "    print(\"  - SOURIS : Dessiner un rectangle autour de l'objet\")\n",
    "    print(\"  - 'r'    : R√©initialiser la s√©lection\")\n",
    "    print(\"  - 'q'    : Quitter\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Miroir pour une interaction plus naturelle\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        # Si une zone est s√©lectionn√©e\n",
    "        if selection_rect is not None and selection_rect[2] > 0 and selection_rect[3] > 0:\n",
    "            x, y, w, h = selection_rect\n",
    "            \n",
    "            # Dessin du rectangle de s√©lection\n",
    "            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            \n",
    "            # Extraction de la ROI (Region of Interest) actuelle\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            # On a besoin de l'image pr√©c√©dente pour calculer le flot\n",
    "            if prev_roi_frame is not None and prev_roi_frame.shape == roi_gray.shape:\n",
    "                \n",
    "                # --- CALCUL DU FLOT OPTIQUE (FARNEBACK) ---\n",
    "                flow = cv2.calcOpticalFlowFarneback(prev_roi_frame, roi_gray, None, **FARNEBACK_PARAMS)\n",
    "                \n",
    "                # --- ANALYSE ---\n",
    "                speed, angle, mask, mag_map, _ = analyze_flow_in_roi(flow, roi_gray)\n",
    "                \n",
    "                # --- VISUALISATION ---\n",
    "                # 1. Dessiner les vecteurs (lignes vertes)\n",
    "                # On parcourt la grille avec un pas (STEP)\n",
    "                for r in range(0, h, STEP):\n",
    "                    for c in range(0, w, STEP):\n",
    "                        # On ne dessine que si le mouvement est significatif √† cet endroit\n",
    "                        if mask[r, c]:\n",
    "                            # Point de d√©part (dans l'image globale)\n",
    "                            start_pt = (x + c, y + r)\n",
    "                            # Vecteur flot\n",
    "                            fx, fy = flow[r, c]\n",
    "                            # Point d'arriv√©e (agrandi x2 pour la visibilit√©)\n",
    "                            end_pt = (int(x + c + fx * 2), int(y + r + fy * 2))\n",
    "                            \n",
    "                            cv2.arrowedLine(display_frame, start_pt, end_pt, (0, 255, 0), 1, tipLength=0.3)\n",
    "\n",
    "                # 2. Afficher les statistiques\n",
    "                direction_text = get_cardinal_direction(angle) if speed > 0.5 else \"Stable\"\n",
    "                \n",
    "                # Barre d'info\n",
    "                info_text = f\"Vitesse: {speed:.2f} px/frame | Direction: {direction_text} ({angle:.0f} deg)\"\n",
    "                cv2.putText(display_frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                \n",
    "                # 3. Code couleur de l'√©tat\n",
    "                if speed > 10:\n",
    "                    status = \"MOUVEMENT RAPIDE\"\n",
    "                    color = (0, 0, 255) # Rouge\n",
    "                elif speed > 0.5:\n",
    "                    status = \"MOUVEMENT LENT\"\n",
    "                    color = (0, 255, 0) # Vert\n",
    "                else:\n",
    "                    status = \"IMMOBILE\"\n",
    "                    color = (200, 200, 200) # Gris\n",
    "                    \n",
    "                cv2.putText(display_frame, status, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            # Mise √† jour pour la frame suivante\n",
    "            prev_roi_frame = roi_gray.copy()\n",
    "        else:\n",
    "            prev_roi_frame = None\n",
    "            cv2.putText(display_frame, \"Dessinez un rectangle avec la souris\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        if drawing and selection_rect:\n",
    "             x, y, w, h = selection_rect\n",
    "             cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Flot Optique - Farneback', display_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('r'):\n",
    "            selection_rect = None\n",
    "            prev_roi_frame = None\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57950d3-e89d-4bea-9fbc-7ab7b5178d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers YOLO manquants. Passage en mode MANUEL.\n",
      "D√©marrage. MODE: MANUEL (Souris)\n",
      "Note: Pour utiliser YOLO, placez 'yolov3-tiny.weights' et 'yolov3-tiny.cfg' dans le dossier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moura\\AppData\\Local\\Temp\\ipykernel_45744\\2516172946.py:166: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  idx = int((angle + 22.5) / 45.0) % 8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "from collections import deque\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FARNEBACK_PARAMS = dict(\n",
    "    pyr_scale=0.5,\n",
    "    levels=3,\n",
    "    winsize=15,\n",
    "    iterations=3,\n",
    "    poly_n=5,\n",
    "    poly_sigma=1.2,\n",
    "    flags=0\n",
    ")\n",
    "\n",
    "# Param√®tres d'analyse\n",
    "MAGNITUDE_THRESHOLD = 2.0  # Seuil de bruit pour le mouvement\n",
    "HISTORY_LENGTH = 30        # Nombre de frames pour l'analyse temporelle (approx 1 sec)\n",
    "WAVE_THRESHOLD = 3         # Nombre d'inversions de direction pour valider un \"Coucou\"\n",
    "\n",
    "# Param√®tres YOLO\n",
    "YOLO_CONFIG = \"yolov3-tiny.cfg\"\n",
    "YOLO_WEIGHTS = \"yolov3-tiny.weights\"\n",
    "YOLO_CLASSES = \"coco.names\"\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "NMS_THRESHOLD = 0.4\n",
    "\n",
    "# --- CLASSE D'ANALYSE DE GESTES ---\n",
    "class GestureAnalyzer:\n",
    "    def __init__(self, maxlen=30):\n",
    "        self.history_fx = deque(maxlen=maxlen) # Vitesse horizontale\n",
    "        self.history_speed = deque(maxlen=maxlen) # Vitesse globale\n",
    "        \n",
    "    def update(self, avg_fx, avg_speed):\n",
    "        self.history_fx.append(avg_fx)\n",
    "        self.history_speed.append(avg_speed)\n",
    "        \n",
    "    def detect_gesture(self):\n",
    "        if len(self.history_speed) < 10:\n",
    "            return \"Analyse...\"\n",
    "\n",
    "        # 1. Analyse de l'immobilit√© (STOP)\n",
    "        recent_speeds = list(self.history_speed)[-10:] # Derni√®res 10 frames\n",
    "        if np.mean(recent_speeds) < 1.0:\n",
    "            return \"STOP (Immobile)\"\n",
    "            \n",
    "        # 2. Analyse de l'oscillation (COUCOU / WAVE)\n",
    "        # On regarde si la vitesse horizontale (fx) change de signe souvent\n",
    "        fx_array = np.array(self.history_fx)\n",
    "        \n",
    "        # On ne consid√®re que les mouvements significatifs pour √©viter le bruit autour de 0\n",
    "        significant_moves = fx_array[np.abs(fx_array) > 0.5]\n",
    "        \n",
    "        if len(significant_moves) > 5:\n",
    "            # Compte les changements de signe (passages par z√©ro)\n",
    "            zero_crossings = np.sum(np.abs(np.diff(np.sign(significant_moves)))) / 2\n",
    "            \n",
    "            if zero_crossings >= WAVE_THRESHOLD:\n",
    "                return \"COUCOU (Wave) üëã\"\n",
    "        \n",
    "        return \"Mouvement...\"\n",
    "\n",
    "# --- GESTION YOLO ---\n",
    "def download_yolo_files():\n",
    "    \"\"\"T√©l√©charge les fichiers YOLOv3-tiny si absents.\"\"\"\n",
    "    base_url = \"https://pjreddie.com/media/files/\"\n",
    "    if not os.path.exists(YOLO_WEIGHTS):\n",
    "        print(f\"T√©l√©chargement de {YOLO_WEIGHTS}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(base_url + YOLO_WEIGHTS, YOLO_WEIGHTS)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur t√©l√©chargement poids: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Note: Le .cfg et coco.names sont souvent requis. \n",
    "    # Pour simplifier, si on ne les a pas, on retournera False dans load_yolo\n",
    "    # Dans un vrai projet, il faudrait aussi les t√©l√©charger depuis un repo github raw.\n",
    "    return True\n",
    "\n",
    "def load_yolo():\n",
    "    # V√©rification basique des fichiers (ici on assume que le user a les fichiers ou qu'on a pu t√©l√©charger les poids)\n",
    "    # Pour ce script autonome, on va essayer de charger, sinon on retourne None\n",
    "    if not os.path.exists(YOLO_WEIGHTS):\n",
    "        print(\"Fichiers YOLO manquants. Passage en mode MANUEL.\")\n",
    "        return None, None, None\n",
    "        \n",
    "    # Cr√©ation d'une config minimale si absente (astuce pour rendre le script portable)\n",
    "    if not os.path.exists(YOLO_CONFIG):\n",
    "        # On ne peut pas inventer la config, il faut que l'utilisateur l'ait.\n",
    "        # Fallback manuel si config manquante.\n",
    "        print(f\"Fichier {YOLO_CONFIG} manquant. Passage en mode MANUEL.\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        net = cv2.dnn.readNetFromDarknet(YOLO_CONFIG, YOLO_WEIGHTS)\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "        layer_names = net.getLayerNames()\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        return net, output_layers, [] # On ignore les classes names pour simplifier\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement YOLO: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def detect_objects_yolo(frame, net, output_layers):\n",
    "    height, width = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # On d√©tecte \"Personne\" (ID 0)\n",
    "            if confidence > CONFIDENCE_THRESHOLD and class_id == 0:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                \n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    \n",
    "    if len(indices) > 0:\n",
    "        # Retourne la bo√Æte la plus confiante\n",
    "        i = indices[0]\n",
    "        # Si i est une liste/tuple (d√©pend version OpenCV), on extrait l'index\n",
    "        if isinstance(i, (tuple, list, np.ndarray)):\n",
    "            i = i.item() \n",
    "        return boxes[i]\n",
    "    return None\n",
    "\n",
    "# --- ANALYSE DU FLOT (Inchang√© mais retourne plus d'infos) ---\n",
    "def analyze_flow_in_roi(flow, roi_gray):\n",
    "    fx, fy = flow[..., 0], flow[..., 1]\n",
    "    mag, ang = cv2.cartToPolar(fx, fy, angleInDegrees=True)\n",
    "    motion_mask = mag > MAGNITUDE_THRESHOLD\n",
    "    \n",
    "    if np.count_nonzero(motion_mask) < 10:\n",
    "        return 0.0, 0.0, 0.0, motion_mask, mag # Ajout fx moyen\n",
    "\n",
    "    avg_speed = np.mean(mag[motion_mask])\n",
    "    avg_fx = np.mean(fx[motion_mask]) # Vitesse horizontale moyenne sign√©e\n",
    "    avg_fy = np.mean(fy[motion_mask])\n",
    "    _, avg_angle = cv2.cartToPolar(np.array([avg_fx]), np.array([avg_fy]), angleInDegrees=True)\n",
    "    \n",
    "    return avg_speed, avg_fx, avg_angle[0], motion_mask, mag\n",
    "\n",
    "def get_cardinal_direction(angle):\n",
    "    directions = [\"Est\", \"Sud-Est\", \"Sud\", \"Sud-Ouest\", \"Ouest\", \"Nord-Ouest\", \"Nord\", \"Nord-Est\"]\n",
    "    idx = int((angle + 22.5) / 45.0) % 8\n",
    "    return directions[idx]\n",
    "\n",
    "# --- VARIABLES GLOBALES SOURIS ---\n",
    "selection_rect = None\n",
    "drawing = False\n",
    "ix, iy = -1, -1\n",
    "\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, selection_rect\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "        selection_rect = None\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            selection_rect = (min(ix, x), min(iy, y), abs(x - ix), abs(y - iy))\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        selection_rect = (min(ix, x), min(iy, y), abs(x - ix), abs(y - iy))\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "def main():\n",
    "    global selection_rect\n",
    "    \n",
    "    # 1. Tentative de chargement YOLO\n",
    "    # On essaye de t√©l√©charger les poids si absents (pour d√©mo)\n",
    "    # download_yolo_files() # D√©commenter pour tenter le t√©l√©chargement auto\n",
    "    \n",
    "    net, output_layers, _ = load_yolo()\n",
    "    use_yolo = (net is not None)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur webcam\")\n",
    "        return\n",
    "\n",
    "    window_name = 'Analyse Mouvement + Gestes'\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.setMouseCallback(window_name, draw_rectangle)\n",
    "\n",
    "    prev_roi_frame = None\n",
    "    gesture_analyzer = GestureAnalyzer(maxlen=HISTORY_LENGTH)\n",
    "    \n",
    "    mode_text = \"MODE: YOLO (Auto)\" if use_yolo else \"MODE: MANUEL (Souris)\"\n",
    "    print(f\"D√©marrage. {mode_text}\")\n",
    "    if not use_yolo:\n",
    "        print(\"Note: Pour utiliser YOLO, placez 'yolov3-tiny.weights' et 'yolov3-tiny.cfg' dans le dossier.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        current_box = None\n",
    "\n",
    "        # --- √âTAPE 1: D√âTECTION (YOLO ou MANUEL) ---\n",
    "        if use_yolo:\n",
    "            # On d√©tecte toutes les quelques frames pour la perf (ici √† chaque frame pour fluidit√© d√©mo)\n",
    "            detected_box = detect_objects_yolo(frame, net, output_layers)\n",
    "            if detected_box:\n",
    "                selection_rect = tuple(detected_box) # Mise √† jour auto\n",
    "                current_box = selection_rect\n",
    "        else:\n",
    "            # Mode manuel\n",
    "            if selection_rect is not None and selection_rect[2] > 0:\n",
    "                current_box = selection_rect\n",
    "\n",
    "        # --- √âTAPE 2: TRAITEMENT ROI ---\n",
    "        if current_box:\n",
    "            x, y, w, h = current_box\n",
    "            # V√©rification des bornes\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            w = min(w, frame.shape[1] - x)\n",
    "            h = min(h, frame.shape[0] - y)\n",
    "            \n",
    "            if w > 10 and h > 10:\n",
    "                cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 100, 0), 2)\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                \n",
    "                if prev_roi_frame is not None and prev_roi_frame.shape == roi_gray.shape:\n",
    "                    # Calcul Flot\n",
    "                    flow = cv2.calcOpticalFlowFarneback(prev_roi_frame, roi_gray, None, **FARNEBACK_PARAMS)\n",
    "                    \n",
    "                    # Analyse Instantan√©e\n",
    "                    speed, avg_fx, angle, mask, _ = analyze_flow_in_roi(flow, roi_gray)\n",
    "                    \n",
    "                    # Mise √† jour Analyseur Gestes\n",
    "                    gesture_analyzer.update(avg_fx, speed)\n",
    "                    gesture_detected = gesture_analyzer.detect_gesture()\n",
    "                    \n",
    "                    # Visualisation Vecteurs (Sous-√©chantillonnage)\n",
    "                    step = 10\n",
    "                    for r in range(0, h, step):\n",
    "                        for c in range(0, w, step):\n",
    "                            if mask[r, c]:\n",
    "                                cv2.arrowedLine(display_frame, \n",
    "                                              (x+c, y+r), \n",
    "                                              (int(x+c+flow[r,c,0]), int(y+r+flow[r,c,1])), \n",
    "                                              (0, 255, 0), 1, tipLength=0.3)\n",
    "                    \n",
    "                    # Affichage Infos\n",
    "                    cv2.putText(display_frame, f\"Geste: {gesture_detected}\", (x, y-30), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                    \n",
    "                    direction = get_cardinal_direction(angle) if speed > 0.5 else \"-\"\n",
    "                    cv2.putText(display_frame, f\"Vit: {speed:.1f} | Dir: {direction}\", (x, y-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "\n",
    "                prev_roi_frame = roi_gray.copy()\n",
    "            else:\n",
    "                prev_roi_frame = None\n",
    "        else:\n",
    "            prev_roi_frame = None\n",
    "            if not use_yolo:\n",
    "                cv2.putText(display_frame, \"Dessinez un cadre sur l'objet\", (20, 50), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(display_frame, \"Recherche de personne...\", (20, 50), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # UI Info\n",
    "        cv2.putText(display_frame, mode_text, (10, frame.shape[0] - 10), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        if drawing and selection_rect:\n",
    "             dx, dy, dw, dh = selection_rect\n",
    "             cv2.rectangle(display_frame, (dx, dy), (dx + dw, dy + dh), (0, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        if key == ord('r'): selection_rect = None # Reset manuel\n",
    "        if key == ord('m'): # Bascule forc√©e manuel/auto\n",
    "            use_yolo = not use_yolo\n",
    "            selection_rect = None\n",
    "            mode_text = \"MODE: YOLO (Auto)\" if use_yolo else \"MODE: MANUEL\"\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa86ee-fd15-45ef-881c-e488cec0073b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
