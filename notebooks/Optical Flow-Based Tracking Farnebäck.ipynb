{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57950d3-e89d-4bea-9fbc-7ab7b5178d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers YOLO manquants. Passage en mode MANUEL.\n",
      "D√©marrage. MODE: MANUEL (Souris)\n",
      "Note: Pour utiliser YOLO, placez 'yolov3-tiny.weights' et 'yolov3-tiny.cfg' dans le dossier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moura\\AppData\\Local\\Temp\\ipykernel_45744\\2516172946.py:166: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  idx = int((angle + 22.5) / 45.0) % 8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "from collections import deque\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FARNEBACK_PARAMS = dict(\n",
    "    pyr_scale=0.5,\n",
    "    levels=3,\n",
    "    winsize=15,\n",
    "    iterations=3,\n",
    "    poly_n=5,\n",
    "    poly_sigma=1.2,\n",
    "    flags=0\n",
    ")\n",
    "\n",
    "# Param√®tres d'analyse\n",
    "MAGNITUDE_THRESHOLD = 2.0  # Seuil de bruit pour le mouvement\n",
    "HISTORY_LENGTH = 30        # Nombre de frames pour l'analyse temporelle (approx 1 sec)\n",
    "WAVE_THRESHOLD = 3         # Nombre d'inversions de direction pour valider un \"Coucou\"\n",
    "\n",
    "# Param√®tres YOLO\n",
    "YOLO_CONFIG = \"yolov3-tiny.cfg\"\n",
    "YOLO_WEIGHTS = \"yolov3-tiny.weights\"\n",
    "YOLO_CLASSES = \"coco.names\"\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "NMS_THRESHOLD = 0.4\n",
    "\n",
    "# --- CLASSE D'ANALYSE DE GESTES ---\n",
    "class GestureAnalyzer:\n",
    "    def __init__(self, maxlen=30):\n",
    "        self.history_fx = deque(maxlen=maxlen) # Vitesse horizontale\n",
    "        self.history_speed = deque(maxlen=maxlen) # Vitesse globale\n",
    "        \n",
    "    def update(self, avg_fx, avg_speed):\n",
    "        self.history_fx.append(avg_fx)\n",
    "        self.history_speed.append(avg_speed)\n",
    "        \n",
    "    def detect_gesture(self):\n",
    "        if len(self.history_speed) < 10:\n",
    "            return \"Analyse...\"\n",
    "\n",
    "        # 1. Analyse de l'immobilit√© (STOP)\n",
    "        recent_speeds = list(self.history_speed)[-10:] # Derni√®res 10 frames\n",
    "        if np.mean(recent_speeds) < 1.0:\n",
    "            return \"STOP (Immobile)\"\n",
    "            \n",
    "        # 2. Analyse de l'oscillation (COUCOU / WAVE)\n",
    "        # On regarde si la vitesse horizontale (fx) change de signe souvent\n",
    "        fx_array = np.array(self.history_fx)\n",
    "        \n",
    "        # On ne consid√®re que les mouvements significatifs pour √©viter le bruit autour de 0\n",
    "        significant_moves = fx_array[np.abs(fx_array) > 0.5]\n",
    "        \n",
    "        if len(significant_moves) > 5:\n",
    "            # Compte les changements de signe (passages par z√©ro)\n",
    "            zero_crossings = np.sum(np.abs(np.diff(np.sign(significant_moves)))) / 2\n",
    "            \n",
    "            if zero_crossings >= WAVE_THRESHOLD:\n",
    "                return \"COUCOU (Wave) üëã\"\n",
    "        \n",
    "        return \"Mouvement...\"\n",
    "\n",
    "# --- GESTION YOLO ---\n",
    "def download_yolo_files():\n",
    "    \"\"\"T√©l√©charge les fichiers YOLOv3-tiny si absents.\"\"\"\n",
    "    base_url = \"https://pjreddie.com/media/files/\"\n",
    "    if not os.path.exists(YOLO_WEIGHTS):\n",
    "        print(f\"T√©l√©chargement de {YOLO_WEIGHTS}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(base_url + YOLO_WEIGHTS, YOLO_WEIGHTS)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur t√©l√©chargement poids: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Note: Le .cfg et coco.names sont souvent requis. \n",
    "    # Pour simplifier, si on ne les a pas, on retournera False dans load_yolo\n",
    "    # Dans un vrai projet, il faudrait aussi les t√©l√©charger depuis un repo github raw.\n",
    "    return True\n",
    "\n",
    "def load_yolo():\n",
    "    # V√©rification basique des fichiers (ici on assume que le user a les fichiers ou qu'on a pu t√©l√©charger les poids)\n",
    "    # Pour ce script autonome, on va essayer de charger, sinon on retourne None\n",
    "    if not os.path.exists(YOLO_WEIGHTS):\n",
    "        print(\"Fichiers YOLO manquants. Passage en mode MANUEL.\")\n",
    "        return None, None, None\n",
    "        \n",
    "    # Cr√©ation d'une config minimale si absente (astuce pour rendre le script portable)\n",
    "    if not os.path.exists(YOLO_CONFIG):\n",
    "        # On ne peut pas inventer la config, il faut que l'utilisateur l'ait.\n",
    "        # Fallback manuel si config manquante.\n",
    "        print(f\"Fichier {YOLO_CONFIG} manquant. Passage en mode MANUEL.\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        net = cv2.dnn.readNetFromDarknet(YOLO_CONFIG, YOLO_WEIGHTS)\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "        layer_names = net.getLayerNames()\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        return net, output_layers, [] # On ignore les classes names pour simplifier\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement YOLO: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def detect_objects_yolo(frame, net, output_layers):\n",
    "    height, width = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # On d√©tecte \"Personne\" (ID 0)\n",
    "            if confidence > CONFIDENCE_THRESHOLD and class_id == 0:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                \n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    \n",
    "    if len(indices) > 0:\n",
    "        # Retourne la bo√Æte la plus confiante\n",
    "        i = indices[0]\n",
    "        # Si i est une liste/tuple (d√©pend version OpenCV), on extrait l'index\n",
    "        if isinstance(i, (tuple, list, np.ndarray)):\n",
    "            i = i.item() \n",
    "        return boxes[i]\n",
    "    return None\n",
    "\n",
    "# --- ANALYSE DU FLOT (Inchang√© mais retourne plus d'infos) ---\n",
    "def analyze_flow_in_roi(flow, roi_gray):\n",
    "    fx, fy = flow[..., 0], flow[..., 1]\n",
    "    mag, ang = cv2.cartToPolar(fx, fy, angleInDegrees=True)\n",
    "    motion_mask = mag > MAGNITUDE_THRESHOLD\n",
    "    \n",
    "    if np.count_nonzero(motion_mask) < 10:\n",
    "        return 0.0, 0.0, 0.0, motion_mask, mag # Ajout fx moyen\n",
    "\n",
    "    avg_speed = np.mean(mag[motion_mask])\n",
    "    avg_fx = np.mean(fx[motion_mask]) # Vitesse horizontale moyenne sign√©e\n",
    "    avg_fy = np.mean(fy[motion_mask])\n",
    "    _, avg_angle = cv2.cartToPolar(np.array([avg_fx]), np.array([avg_fy]), angleInDegrees=True)\n",
    "    \n",
    "    return avg_speed, avg_fx, avg_angle[0], motion_mask, mag\n",
    "\n",
    "def get_cardinal_direction(angle):\n",
    "    directions = [\"Est\", \"Sud-Est\", \"Sud\", \"Sud-Ouest\", \"Ouest\", \"Nord-Ouest\", \"Nord\", \"Nord-Est\"]\n",
    "    idx = int((angle + 22.5) / 45.0) % 8\n",
    "    return directions[idx]\n",
    "\n",
    "# --- VARIABLES GLOBALES SOURIS ---\n",
    "selection_rect = None\n",
    "drawing = False\n",
    "ix, iy = -1, -1\n",
    "\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, selection_rect\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "        selection_rect = None\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            selection_rect = (min(ix, x), min(iy, y), abs(x - ix), abs(y - iy))\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        selection_rect = (min(ix, x), min(iy, y), abs(x - ix), abs(y - iy))\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "def main():\n",
    "    global selection_rect\n",
    "    \n",
    "    # 1. Tentative de chargement YOLO\n",
    "    # On essaye de t√©l√©charger les poids si absents (pour d√©mo)\n",
    "    # download_yolo_files() # D√©commenter pour tenter le t√©l√©chargement auto\n",
    "    \n",
    "    net, output_layers, _ = load_yolo()\n",
    "    use_yolo = (net is not None)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur webcam\")\n",
    "        return\n",
    "\n",
    "    window_name = 'Analyse Mouvement + Gestes'\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.setMouseCallback(window_name, draw_rectangle)\n",
    "\n",
    "    prev_roi_frame = None\n",
    "    gesture_analyzer = GestureAnalyzer(maxlen=HISTORY_LENGTH)\n",
    "    \n",
    "    mode_text = \"MODE: YOLO (Auto)\" if use_yolo else \"MODE: MANUEL (Souris)\"\n",
    "    print(f\"D√©marrage. {mode_text}\")\n",
    "    if not use_yolo:\n",
    "        print(\"Note: Pour utiliser YOLO, placez 'yolov3-tiny.weights' et 'yolov3-tiny.cfg' dans le dossier.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        current_box = None\n",
    "\n",
    "        # --- √âTAPE 1: D√âTECTION (YOLO ou MANUEL) ---\n",
    "        if use_yolo:\n",
    "            # On d√©tecte toutes les quelques frames pour la perf (ici √† chaque frame pour fluidit√© d√©mo)\n",
    "            detected_box = detect_objects_yolo(frame, net, output_layers)\n",
    "            if detected_box:\n",
    "                selection_rect = tuple(detected_box) # Mise √† jour auto\n",
    "                current_box = selection_rect\n",
    "        else:\n",
    "            # Mode manuel\n",
    "            if selection_rect is not None and selection_rect[2] > 0:\n",
    "                current_box = selection_rect\n",
    "\n",
    "        # --- √âTAPE 2: TRAITEMENT ROI ---\n",
    "        if current_box:\n",
    "            x, y, w, h = current_box\n",
    "            # V√©rification des bornes\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            w = min(w, frame.shape[1] - x)\n",
    "            h = min(h, frame.shape[0] - y)\n",
    "            \n",
    "            if w > 10 and h > 10:\n",
    "                cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 100, 0), 2)\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                \n",
    "                if prev_roi_frame is not None and prev_roi_frame.shape == roi_gray.shape:\n",
    "                    # Calcul Flot\n",
    "                    flow = cv2.calcOpticalFlowFarneback(prev_roi_frame, roi_gray, None, **FARNEBACK_PARAMS)\n",
    "                    \n",
    "                    # Analyse Instantan√©e\n",
    "                    speed, avg_fx, angle, mask, _ = analyze_flow_in_roi(flow, roi_gray)\n",
    "                    \n",
    "                    # Mise √† jour Analyseur Gestes\n",
    "                    gesture_analyzer.update(avg_fx, speed)\n",
    "                    gesture_detected = gesture_analyzer.detect_gesture()\n",
    "                    \n",
    "                    # Visualisation Vecteurs (Sous-√©chantillonnage)\n",
    "                    step = 10\n",
    "                    for r in range(0, h, step):\n",
    "                        for c in range(0, w, step):\n",
    "                            if mask[r, c]:\n",
    "                                cv2.arrowedLine(display_frame, \n",
    "                                              (x+c, y+r), \n",
    "                                              (int(x+c+flow[r,c,0]), int(y+r+flow[r,c,1])), \n",
    "                                              (0, 255, 0), 1, tipLength=0.3)\n",
    "                    \n",
    "                    # Affichage Infos\n",
    "                    cv2.putText(display_frame, f\"Geste: {gesture_detected}\", (x, y-30), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                    \n",
    "                    direction = get_cardinal_direction(angle) if speed > 0.5 else \"-\"\n",
    "                    cv2.putText(display_frame, f\"Vit: {speed:.1f} | Dir: {direction}\", (x, y-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "\n",
    "                prev_roi_frame = roi_gray.copy()\n",
    "            else:\n",
    "                prev_roi_frame = None\n",
    "        else:\n",
    "            prev_roi_frame = None\n",
    "            if not use_yolo:\n",
    "                cv2.putText(display_frame, \"Dessinez un cadre sur l'objet\", (20, 50), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(display_frame, \"Recherche de personne...\", (20, 50), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # UI Info\n",
    "        cv2.putText(display_frame, mode_text, (10, frame.shape[0] - 10), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        if drawing and selection_rect:\n",
    "             dx, dy, dw, dh = selection_rect\n",
    "             cv2.rectangle(display_frame, (dx, dy), (dx + dw, dy + dh), (0, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        if key == ord('r'): selection_rect = None # Reset manuel\n",
    "        if key == ord('m'): # Bascule forc√©e manuel/auto\n",
    "            use_yolo = not use_yolo\n",
    "            selection_rect = None\n",
    "            mode_text = \"MODE: YOLO (Auto)\" if use_yolo else \"MODE: MANUEL\"\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa86ee-fd15-45ef-881c-e488cec0073b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
